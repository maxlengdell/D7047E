{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import tensorboard\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading  and  preparing  CIFAR-10  dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.Resize(224),\n",
    "     transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4,\n",
    "                                          shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=4,\n",
    "                                         shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "#images, labels = next(iter(trainloader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Downloading AlexNet and adding fully connected layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\andre/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n",
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-4df8aa71.pth\" to C:\\Users\\andre/.cache\\torch\\hub\\checkpoints\\alexnet-owt-4df8aa71.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6590e0a4a43c41f5bd09ed4198aa6a20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "model.classifier[6] = nn.Linear(4096,10)\n",
    "model.eval()\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\andre/.cache\\torch\\hub\\pytorch_vision_v0.9.0\n"
     ]
    }
   ],
   "source": [
    "model_2 = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_2.parameters(), lr=0.0001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AlexNet(\n",
       "  (features): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(11, 11), stride=(4, 4), padding=(2, 2))\n",
       "    (1): ReLU(inplace=True)\n",
       "    (2): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 192, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2))\n",
       "    (4): ReLU(inplace=True)\n",
       "    (5): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU(inplace=True)\n",
       "    (8): Conv2d(384, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (9): ReLU(inplace=True)\n",
       "    (10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (11): ReLU(inplace=True)\n",
       "    (12): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(6, 6))\n",
       "  (classifier): Sequential(\n",
       "    (0): Dropout(p=0.5, inplace=False)\n",
       "    (1): Linear(in_features=9216, out_features=4096, bias=True)\n",
       "    (2): ReLU(inplace=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=4096, out_features=4096, bias=True)\n",
       "    (5): ReLU(inplace=True)\n",
       "    (6): Linear(in_features=4096, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for param in model_2.parameters():\n",
    "    param.requeires_grad = False\n",
    "model_2.classifier[6] = nn.Linear(4096,10)\n",
    "\n",
    "model_2.eval()\n",
    "model_2.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finetuning / Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 2.302\n",
      "Accuracy:  0.108125\n",
      "[1,  4000] loss: 2.302\n",
      "Accuracy:  0.104625\n",
      "[1,  6000] loss: 2.302\n",
      "Accuracy:  0.10845833333333334\n",
      "[1,  8000] loss: 2.301\n",
      "Accuracy:  0.1110625\n",
      "[1, 10000] loss: 2.300\n",
      "Accuracy:  0.124225\n",
      "[1, 12000] loss: 2.297\n",
      "Accuracy:  0.1338125\n",
      "[2,  2000] loss: 2.277\n",
      "Accuracy:  0.17375\n",
      "[2,  4000] loss: 2.072\n",
      "Accuracy:  0.2135625\n",
      "[2,  6000] loss: 1.919\n",
      "Accuracy:  0.24270833333333333\n",
      "[2,  8000] loss: 1.810\n",
      "Accuracy:  0.269375\n",
      "[2, 10000] loss: 1.719\n",
      "Accuracy:  0.2903\n",
      "[2, 12000] loss: 1.651\n",
      "Accuracy:  0.3071875\n",
      "[3,  2000] loss: 1.592\n",
      "Accuracy:  0.419375\n",
      "[3,  4000] loss: 1.559\n",
      "Accuracy:  0.4241875\n",
      "[3,  6000] loss: 1.525\n",
      "Accuracy:  0.43083333333333335\n",
      "[3,  8000] loss: 1.499\n",
      "Accuracy:  0.43484375\n",
      "[3, 10000] loss: 1.464\n",
      "Accuracy:  0.4422\n",
      "[3, 12000] loss: 1.434\n",
      "Accuracy:  0.4488333333333333\n",
      "[4,  2000] loss: 1.401\n",
      "Accuracy:  0.48975\n",
      "[4,  4000] loss: 1.369\n",
      "Accuracy:  0.4965625\n",
      "[4,  6000] loss: 1.354\n",
      "Accuracy:  0.5040833333333333\n",
      "[4,  8000] loss: 1.352\n",
      "Accuracy:  0.5058125\n",
      "[4, 10000] loss: 1.307\n",
      "Accuracy:  0.510425\n",
      "[4, 12000] loss: 1.303\n",
      "Accuracy:  0.515375\n",
      "[5,  2000] loss: 1.261\n",
      "Accuracy:  0.553\n",
      "[5,  4000] loss: 1.227\n",
      "Accuracy:  0.561875\n",
      "[5,  6000] loss: 1.204\n",
      "Accuracy:  0.5625416666666667\n",
      "[5,  8000] loss: 1.188\n",
      "Accuracy:  0.5663125\n",
      "[5, 10000] loss: 1.188\n",
      "Accuracy:  0.569575\n",
      "[5, 12000] loss: 1.170\n",
      "Accuracy:  0.5720416666666667\n",
      "[6,  2000] loss: 1.115\n",
      "Accuracy:  0.609125\n",
      "[6,  4000] loss: 1.083\n",
      "Accuracy:  0.6118125\n",
      "[6,  6000] loss: 1.064\n",
      "Accuracy:  0.6145833333333334\n",
      "[6,  8000] loss: 1.066\n",
      "Accuracy:  0.6179375\n",
      "[6, 10000] loss: 1.041\n",
      "Accuracy:  0.622025\n",
      "[6, 12000] loss: 1.031\n",
      "Accuracy:  0.6260416666666667\n",
      "[7,  2000] loss: 0.956\n",
      "Accuracy:  0.660125\n",
      "[7,  4000] loss: 0.943\n",
      "Accuracy:  0.6671875\n",
      "[7,  6000] loss: 0.935\n",
      "Accuracy:  0.6689583333333333\n",
      "[7,  8000] loss: 0.929\n",
      "Accuracy:  0.670625\n",
      "[7, 10000] loss: 0.912\n",
      "Accuracy:  0.671925\n",
      "[7, 12000] loss: 0.921\n",
      "Accuracy:  0.6722291666666667\n",
      "[8,  2000] loss: 0.823\n",
      "Accuracy:  0.7115\n",
      "[8,  4000] loss: 0.829\n",
      "Accuracy:  0.712125\n",
      "[8,  6000] loss: 0.804\n",
      "Accuracy:  0.7135833333333333\n",
      "[8,  8000] loss: 0.815\n",
      "Accuracy:  0.7149375\n",
      "[8, 10000] loss: 0.793\n",
      "Accuracy:  0.716525\n",
      "[8, 12000] loss: 0.807\n",
      "Accuracy:  0.7172708333333333\n",
      "[9,  2000] loss: 0.702\n",
      "Accuracy:  0.753625\n",
      "[9,  4000] loss: 0.701\n",
      "Accuracy:  0.755125\n",
      "[9,  6000] loss: 0.695\n",
      "Accuracy:  0.756125\n",
      "[9,  8000] loss: 0.711\n",
      "Accuracy:  0.75471875\n",
      "[9, 10000] loss: 0.701\n",
      "Accuracy:  0.753425\n",
      "[9, 12000] loss: 0.669\n",
      "Accuracy:  0.7562708333333333\n",
      "[10,  2000] loss: 0.568\n",
      "Accuracy:  0.799\n",
      "[10,  4000] loss: 0.581\n",
      "Accuracy:  0.7976875\n",
      "[10,  6000] loss: 0.583\n",
      "Accuracy:  0.7975\n",
      "[10,  8000] loss: 0.593\n",
      "Accuracy:  0.79609375\n",
      "[10, 10000] loss: 0.583\n",
      "Accuracy:  0.795125\n",
      "[10, 12000] loss: 0.595\n",
      "Accuracy:  0.794875\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model(inputs).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "#         writer.add_scalar('Loss/train', loss.item(), i)\n",
    "#         writer.add_scalar('Accuracy/train', correct/total, i)\n",
    "       \n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            print(\"Accuracy: \", correct/total)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training (Feature Extraction, only training last layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1,  2000] loss: 1.267\n",
      "Accuracy:  0.552625\n",
      "[1,  4000] loss: 0.763\n",
      "Accuracy:  0.6420625\n",
      "[1,  6000] loss: 0.632\n",
      "Accuracy:  0.6890416666666667\n",
      "[1,  8000] loss: 0.578\n",
      "Accuracy:  0.7175625\n",
      "[1, 10000] loss: 0.520\n",
      "Accuracy:  0.7381\n",
      "[1, 12000] loss: 0.493\n",
      "Accuracy:  0.7528541666666667\n",
      "[2,  2000] loss: 0.427\n",
      "Accuracy:  0.849625\n",
      "[2,  4000] loss: 0.398\n",
      "Accuracy:  0.855125\n",
      "[2,  6000] loss: 0.385\n",
      "Accuracy:  0.8594583333333333\n",
      "[2,  8000] loss: 0.397\n",
      "Accuracy:  0.86040625\n",
      "[2, 10000] loss: 0.376\n",
      "Accuracy:  0.8623\n",
      "[2, 12000] loss: 0.364\n",
      "Accuracy:  0.8644791666666667\n",
      "[3,  2000] loss: 0.306\n",
      "Accuracy:  0.8955\n",
      "[3,  4000] loss: 0.292\n",
      "Accuracy:  0.89575\n",
      "[3,  6000] loss: 0.307\n",
      "Accuracy:  0.8959583333333333\n",
      "[3,  8000] loss: 0.294\n",
      "Accuracy:  0.89690625\n",
      "[3, 10000] loss: 0.288\n",
      "Accuracy:  0.8975\n",
      "[3, 12000] loss: 0.289\n",
      "Accuracy:  0.8976666666666666\n",
      "[4,  2000] loss: 0.230\n",
      "Accuracy:  0.923875\n",
      "[4,  4000] loss: 0.223\n",
      "Accuracy:  0.92475\n",
      "[4,  6000] loss: 0.225\n",
      "Accuracy:  0.9236666666666666\n",
      "[4,  8000] loss: 0.231\n",
      "Accuracy:  0.9215625\n",
      "[4, 10000] loss: 0.246\n",
      "Accuracy:  0.92075\n",
      "[4, 12000] loss: 0.230\n",
      "Accuracy:  0.9204375\n",
      "[5,  2000] loss: 0.167\n",
      "Accuracy:  0.945875\n",
      "[5,  4000] loss: 0.180\n",
      "Accuracy:  0.94275\n",
      "[5,  6000] loss: 0.196\n",
      "Accuracy:  0.938875\n",
      "[5,  8000] loss: 0.194\n",
      "Accuracy:  0.9379375\n",
      "[5, 10000] loss: 0.181\n",
      "Accuracy:  0.938025\n",
      "[5, 12000] loss: 0.183\n",
      "Accuracy:  0.937875\n",
      "[6,  2000] loss: 0.131\n",
      "Accuracy:  0.957875\n",
      "[6,  4000] loss: 0.144\n",
      "Accuracy:  0.95375\n",
      "[6,  6000] loss: 0.132\n",
      "Accuracy:  0.9542916666666666\n",
      "[6,  8000] loss: 0.150\n",
      "Accuracy:  0.952625\n",
      "[6, 10000] loss: 0.145\n",
      "Accuracy:  0.95195\n",
      "[6, 12000] loss: 0.158\n",
      "Accuracy:  0.950875\n",
      "[7,  2000] loss: 0.097\n",
      "Accuracy:  0.969625\n",
      "[7,  4000] loss: 0.109\n",
      "Accuracy:  0.967\n",
      "[7,  6000] loss: 0.115\n",
      "Accuracy:  0.9657083333333333\n",
      "[7,  8000] loss: 0.110\n",
      "Accuracy:  0.96490625\n",
      "[7, 10000] loss: 0.110\n",
      "Accuracy:  0.964875\n",
      "[7, 12000] loss: 0.105\n",
      "Accuracy:  0.9652083333333333\n",
      "[8,  2000] loss: 0.076\n",
      "Accuracy:  0.97825\n",
      "[8,  4000] loss: 0.085\n",
      "Accuracy:  0.97525\n",
      "[8,  6000] loss: 0.075\n",
      "Accuracy:  0.9751666666666666\n",
      "[8,  8000] loss: 0.080\n",
      "Accuracy:  0.97484375\n",
      "[8, 10000] loss: 0.086\n",
      "Accuracy:  0.974175\n",
      "[8, 12000] loss: 0.081\n",
      "Accuracy:  0.9740208333333333\n",
      "[9,  2000] loss: 0.047\n",
      "Accuracy:  0.985875\n",
      "[9,  4000] loss: 0.060\n",
      "Accuracy:  0.9835625\n",
      "[9,  6000] loss: 0.065\n",
      "Accuracy:  0.982\n",
      "[9,  8000] loss: 0.054\n",
      "Accuracy:  0.98221875\n",
      "[9, 10000] loss: 0.061\n",
      "Accuracy:  0.981625\n",
      "[9, 12000] loss: 0.064\n",
      "Accuracy:  0.9812083333333333\n",
      "[10,  2000] loss: 0.039\n",
      "Accuracy:  0.990125\n",
      "[10,  4000] loss: 0.040\n",
      "Accuracy:  0.989\n",
      "[10,  6000] loss: 0.035\n",
      "Accuracy:  0.9896666666666667\n",
      "[10,  8000] loss: 0.040\n",
      "Accuracy:  0.98925\n",
      "[10, 10000] loss: 0.042\n",
      "Accuracy:  0.988925\n",
      "[10, 12000] loss: 0.043\n",
      "Accuracy:  0.9886666666666667\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(10):  # loop over the dataset multiple times\n",
    "\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "    for i, data in enumerate(trainloader, 0):\n",
    "        # get the inputs; data is a list of [inputs, labels]\n",
    "        inputs, labels = data[0].to(device), data[1].to(device)\n",
    "        #inputs, labels = data\n",
    "        \n",
    "        # zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward + backward + optimize\n",
    "        outputs = model_2(inputs).to(device)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # print statistics\n",
    "        running_loss += loss.item()\n",
    "#         writer.add_scalar('Loss/train', loss.item(), i)\n",
    "#         writer.add_scalar('Accuracy/train', correct/total, i)\n",
    "       \n",
    "        if i % 2000 == 1999:    # print every 2000 mini-batches\n",
    "            print('[%d, %5d] loss: %.3f' %\n",
    "                  (epoch + 1, i + 1, running_loss / 2000))\n",
    "            running_loss = 0.0\n",
    "            print(\"Accuracy: \", correct/total)\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (on finetuned model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 72 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        #images, labels = data\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing (AlexNet as Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 89 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data[0].to(device), data[1].to(device)\n",
    "        #images, labels = data\n",
    "        outputs = model_2(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "    100 * correct / total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning from MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_2 = torch.hub.load('pytorch/vision:v0.9.0', 'alexnet', pretrained=True)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model_2.parameters(), lr=0.0001, momentum=0.9)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
